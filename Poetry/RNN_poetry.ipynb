{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXzW1t6Zmdpg"
      },
      "source": [
        "Importing libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAiZRzQcTTVS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzKfP83n6LgH"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI78aHx56Jvk"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt \\\n",
        "    -O /tmp/irish-lyrics-eof.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG4p2zvYzbke"
      },
      "outputs": [],
      "source": [
        "#we dont need a validation dataset for generating text\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "#stored as a single string\n",
        "data = open('/tmp/irish-lyrics-eof.txt').read()\n",
        "\n",
        "#number of sentences by splitting the string\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "#fit tokenizer in text to get word index\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "#add 1 to the length of word indexfor vocabulary index to \n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckqAbvrv79R5"
      },
      "outputs": [],
      "source": [
        "#turn them into training data as we've a list of tokenized sentences\n",
        "\n",
        "#create list of empty input sequences\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\t#for each line of corpus we'll create list of tokens\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "#n_gram_sequences is basically a list of broken down sequences from the original sentence\n",
        "#like the 1st two , 1st three and so on , we are doing this so the model is trained well\n",
        "#so when we see these two words this one is next, \n",
        "#\"   \"\t  \"  \"    \"    threee words \"  \"  \"  \" ans so on \n",
        "\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\t\n",
        "# pad sequences \n",
        "#start by getting length of the longest sentences, \n",
        "#pad everything with a 0 upto length max sent\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "#we want y to be categorical & one hot encoded \n",
        "#so when we train, we'll be able to predict all words in our corpus\n",
        "#which one is the  most likely sequence to next in the sequnece\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dbBK0IFg8Qb"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYm-WPuIg_Tp"
      },
      "outputs": [],
      "source": [
        "print(xs[6])\n",
        "print(ys[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYzHBsHTr9dc"
      },
      "outputs": [],
      "source": [
        "print(xs[5])\n",
        "print(ys[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFrKAQAVhCKb"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XxV9efKu7mm",
        "outputId": "9f44daf2-fc40-4a51-cd98-0a20f3d1e5db"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "377/377 [==============================] - 32s 75ms/step - loss: 6.6451 - accuracy: 0.0728\n",
            "Epoch 2/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 5.8027 - accuracy: 0.1123\n",
            "Epoch 3/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 4.9032 - accuracy: 0.1625\n",
            "Epoch 4/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 3.9564 - accuracy: 0.2367\n",
            "Epoch 5/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 3.1151 - accuracy: 0.3385\n",
            "Epoch 6/100\n",
            "377/377 [==============================] - 29s 76ms/step - loss: 2.4580 - accuracy: 0.4471\n",
            "Epoch 7/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 2.0129 - accuracy: 0.5252\n",
            "Epoch 8/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 1.6545 - accuracy: 0.6060\n",
            "Epoch 9/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 1.3744 - accuracy: 0.6704\n",
            "Epoch 10/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.1812 - accuracy: 0.7152\n",
            "Epoch 11/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.1283 - accuracy: 0.7245\n",
            "Epoch 12/100\n",
            "377/377 [==============================] - 29s 76ms/step - loss: 1.1437 - accuracy: 0.7130\n",
            "Epoch 13/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.2001 - accuracy: 0.6944\n",
            "Epoch 14/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.1855 - accuracy: 0.7009\n",
            "Epoch 15/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.1038 - accuracy: 0.7133\n",
            "Epoch 16/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.0294 - accuracy: 0.7323\n",
            "Epoch 17/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 0.9971 - accuracy: 0.7423\n",
            "Epoch 18/100\n",
            "377/377 [==============================] - 29s 76ms/step - loss: 0.9654 - accuracy: 0.7553\n",
            "Epoch 19/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 0.9874 - accuracy: 0.7464\n",
            "Epoch 20/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.0269 - accuracy: 0.7358\n",
            "Epoch 21/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.0207 - accuracy: 0.7358\n",
            "Epoch 22/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.0080 - accuracy: 0.7353\n",
            "Epoch 23/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.0071 - accuracy: 0.7327\n",
            "Epoch 24/100\n",
            "377/377 [==============================] - 29s 76ms/step - loss: 1.0061 - accuracy: 0.7347\n",
            "Epoch 25/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 0.9482 - accuracy: 0.7446\n",
            "Epoch 26/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 0.9004 - accuracy: 0.7637\n",
            "Epoch 27/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 0.8700 - accuracy: 0.7716\n",
            "Epoch 28/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 0.8698 - accuracy: 0.7726\n",
            "Epoch 29/100\n",
            "377/377 [==============================] - 27s 71ms/step - loss: 0.8654 - accuracy: 0.7711\n",
            "Epoch 30/100\n",
            "377/377 [==============================] - 28s 76ms/step - loss: 0.8838 - accuracy: 0.7686\n",
            "Epoch 31/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 0.9311 - accuracy: 0.7539\n",
            "Epoch 32/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 1.0732 - accuracy: 0.7215\n",
            "Epoch 33/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 1.0787 - accuracy: 0.7142\n",
            "Epoch 34/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.0177 - accuracy: 0.7314\n",
            "Epoch 35/100\n",
            "377/377 [==============================] - 27s 71ms/step - loss: 0.9697 - accuracy: 0.7468\n",
            "Epoch 36/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9461 - accuracy: 0.7480\n",
            "Epoch 37/100\n",
            "377/377 [==============================] - 27s 71ms/step - loss: 0.9209 - accuracy: 0.7588\n",
            "Epoch 38/100\n",
            "377/377 [==============================] - 26s 70ms/step - loss: 0.9131 - accuracy: 0.7581\n",
            "Epoch 39/100\n",
            "377/377 [==============================] - 26s 69ms/step - loss: 0.8949 - accuracy: 0.7657\n",
            "Epoch 40/100\n",
            "377/377 [==============================] - 26s 69ms/step - loss: 0.8490 - accuracy: 0.7740\n",
            "Epoch 41/100\n",
            "377/377 [==============================] - 26s 69ms/step - loss: 0.8946 - accuracy: 0.7657\n",
            "Epoch 42/100\n",
            "377/377 [==============================] - 27s 71ms/step - loss: 1.0089 - accuracy: 0.7388\n",
            "Epoch 43/100\n",
            "377/377 [==============================] - 27s 70ms/step - loss: 0.9935 - accuracy: 0.7366\n",
            "Epoch 44/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 0.9888 - accuracy: 0.7373\n",
            "Epoch 45/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 0.9268 - accuracy: 0.7541\n",
            "Epoch 46/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8911 - accuracy: 0.7659\n",
            "Epoch 47/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8510 - accuracy: 0.7713\n",
            "Epoch 48/100\n",
            "377/377 [==============================] - 29s 76ms/step - loss: 0.8126 - accuracy: 0.7814\n",
            "Epoch 49/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.8749 - accuracy: 0.7725\n",
            "Epoch 50/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 0.9227 - accuracy: 0.7554\n",
            "Epoch 51/100\n",
            "377/377 [==============================] - 27s 72ms/step - loss: 1.0046 - accuracy: 0.7372\n",
            "Epoch 52/100\n",
            "377/377 [==============================] - 27s 73ms/step - loss: 1.0267 - accuracy: 0.7281\n",
            "Epoch 53/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9753 - accuracy: 0.7377\n",
            "Epoch 54/100\n",
            "377/377 [==============================] - 28s 76ms/step - loss: 0.9101 - accuracy: 0.7563\n",
            "Epoch 55/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.8328 - accuracy: 0.7782\n",
            "Epoch 56/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.7856 - accuracy: 0.7896\n",
            "Epoch 57/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8102 - accuracy: 0.7830\n",
            "Epoch 58/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8953 - accuracy: 0.7598\n",
            "Epoch 59/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.9164 - accuracy: 0.7564\n",
            "Epoch 60/100\n",
            "377/377 [==============================] - 29s 78ms/step - loss: 1.0793 - accuracy: 0.7255\n",
            "Epoch 61/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 1.0218 - accuracy: 0.7304\n",
            "Epoch 62/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.9259 - accuracy: 0.7543\n",
            "Epoch 63/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8878 - accuracy: 0.7637\n",
            "Epoch 64/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.7918 - accuracy: 0.7881\n",
            "Epoch 65/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.8132 - accuracy: 0.7829\n",
            "Epoch 66/100\n",
            "377/377 [==============================] - 29s 77ms/step - loss: 0.9172 - accuracy: 0.7637\n",
            "Epoch 67/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9194 - accuracy: 0.7576\n",
            "Epoch 68/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 1.1402 - accuracy: 0.7117\n",
            "Epoch 69/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 1.0127 - accuracy: 0.7363\n",
            "Epoch 70/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 1.0333 - accuracy: 0.7328\n",
            "Epoch 71/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9428 - accuracy: 0.7510\n",
            "Epoch 72/100\n",
            "377/377 [==============================] - 29s 78ms/step - loss: 0.8621 - accuracy: 0.7695\n",
            "Epoch 73/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.8000 - accuracy: 0.7846\n",
            "Epoch 74/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.7836 - accuracy: 0.7937\n",
            "Epoch 75/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.7861 - accuracy: 0.7906\n",
            "Epoch 76/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8261 - accuracy: 0.7805\n",
            "Epoch 77/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9289 - accuracy: 0.7554\n",
            "Epoch 78/100\n",
            "377/377 [==============================] - 29s 76ms/step - loss: 0.9354 - accuracy: 0.7520\n",
            "Epoch 79/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9354 - accuracy: 0.7531\n",
            "Epoch 80/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9713 - accuracy: 0.7490\n",
            "Epoch 81/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 1.0052 - accuracy: 0.7436\n",
            "Epoch 82/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.9354 - accuracy: 0.7538\n",
            "Epoch 83/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.8765 - accuracy: 0.7681\n",
            "Epoch 84/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.8310 - accuracy: 0.7799\n",
            "Epoch 85/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.8133 - accuracy: 0.7854\n",
            "Epoch 86/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.7925 - accuracy: 0.7915\n",
            "Epoch 87/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.7884 - accuracy: 0.7912\n",
            "Epoch 88/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8496 - accuracy: 0.7767\n",
            "Epoch 89/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.9835 - accuracy: 0.7457\n",
            "Epoch 90/100\n",
            "377/377 [==============================] - 29s 76ms/step - loss: 1.0083 - accuracy: 0.7388\n",
            "Epoch 91/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9762 - accuracy: 0.7456\n",
            "Epoch 92/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.9090 - accuracy: 0.7588\n",
            "Epoch 93/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.8726 - accuracy: 0.7710\n",
            "Epoch 94/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8085 - accuracy: 0.7853\n",
            "Epoch 95/100\n",
            "377/377 [==============================] - 29s 76ms/step - loss: 0.7856 - accuracy: 0.7874\n",
            "Epoch 96/100\n",
            "377/377 [==============================] - 28s 73ms/step - loss: 0.7989 - accuracy: 0.7882\n",
            "Epoch 97/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8258 - accuracy: 0.7817\n",
            "Epoch 98/100\n",
            "377/377 [==============================] - 28s 74ms/step - loss: 0.8381 - accuracy: 0.7733\n",
            "Epoch 99/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.8225 - accuracy: 0.7818\n",
            "Epoch 100/100\n",
            "377/377 [==============================] - 28s 75ms/step - loss: 0.8242 - accuracy: 0.7832\n",
            "<keras.engine.sequential.Sequential object at 0x7f25782b8f10>\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "#1st parameter: unique words in the corpus, dimension 100\n",
        "#input length : because looped off the final value in each sequence to make label\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "\n",
        "#made simple LSTM and made it bidirectional\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "\n",
        "#output is dense with total no. pf words ,\n",
        "#labels one hot encoded so output representative of this\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(lr=0.01)\n",
        "\n",
        "#defining loss function and optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "history = model.fit(xs, ys, epochs=100, verbose=1)\n",
        "#print model.summary()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kZizUlYQv1KI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iiHey7Q52fbi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ae885862-5428-424f-c2d4-b5b20545d5e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "plot_graphs(history, 'accuracy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yggmjTN8ijfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd50b35-1d1f-410d-9f57-b705d3d0a3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 858ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "I've got a bad feeling about this crown leave in morning some little stile but in ould faces and the divils and all at divinity high road in rising childer are reel on the road to drumslieve crystal march with faces drawn to fill to me grief said love you tis trod so shining near oer the prime of green and the green down by a river when we safely landed that were gone and the covers buttoned down by my own fireside are on their way i wid you love my own low so dearly so dearly watch and hope and pray an equality then that\n"
          ]
        }
      ],
      "source": [
        "#to generate text, seed it with some text & predict next values\n",
        "seed_text = \"I've got a bad feeling about this\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}